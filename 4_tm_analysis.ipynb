{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Topic Models\n",
    "\n",
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pickle\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSVs\n",
    "* Import df-R-cleaned.csv and df-n.csv from the output of `2_clean.ipynb`. \n",
    "* Then combine both into a new dataframe to use in this session, 'df_all', matching on n_id and id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_R = pd.read_csv('output/df-R-cleaned.csv', encoding='utf-8', na_filter=False) #article metadata\n",
    "df_n = pd.read_csv('output/df-n.csv', encoding='utf-8') #article ngrams\n",
    "df_all = df_R.merge(df_n, left_on='file_name', right_on='n_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on number of articles for analysis\n",
    "Ensure we are excluding the records we previously removed from df_R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_R) < len(df_n) \n",
    "assert len(df_all) == len(df_R) \n",
    "len(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus metadata: Descriptive Statistics\n",
    "Run the numbers here on the basic outlines of the corpus; number of articles per year, per journal, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Articles by year\n",
    "Calculate and plot articles by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_count = df_R.groupby(['pub_year']).count()[['file_name']]\n",
    "year_count.columns = ['article_count']\n",
    "year_count.to_csv('output/articles_per_year.csv', encoding='utf-8', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_year = year_count.index\n",
    "y_count = year_count['article_count']\n",
    "plt.plot(x_year, y_count)\n",
    "plt.ylabel(\"Number of articles\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.title('LQ Corpus: Number of articles per year')\n",
    "#plt.show()\n",
    "plt.savefig('output/lq_tm/plots/art_per_year.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issues by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals = df_R.groupby(['pub_year', 'volume', 'issue']).count()[['file_name']]\n",
    "journals.columns = ['article_count']\n",
    "journals = journals.sort_values('pub_year', ascending=True)\n",
    "journals\n",
    "journals.to_csv('output/articles_per_issue.csv', encoding='utf-8', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of entries = number of journal issues\n",
    "journals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean articles per issue:', journals.article_count.mean()) # cody's number: 22.728070175438596 my number: 23.681286549707604"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean articles per issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals = df_R.groupby(['pub_year']).count()[['file_name']]\n",
    "journals.columns = ['article_count']\n",
    "journals = journals.sort_values('pub_year', ascending=True)\n",
    "journals.article_count.mean() # cody's number: 91.44705882352942 my number: 95.28235294117647\n",
    "journals.to_csv('output/background/articles_per_year.csv', encoding='utf-8', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_articles_issue = journals.groupby(['pub_year']).mean()[['article_count']]\n",
    "mean_articles_issue.to_csv('output/background/mean_articles_per_issue.csv', encoding='utf-8', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_year = mean_articles_issue.index\n",
    "y_count = mean_articles_issue['article_count']\n",
    "plt.plot(x_year, y_count)\n",
    "plt.ylabel(\"Articles per issue\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.title('LQ Corpus: Mean articles per issue')\n",
    "#plt.show()\n",
    "plt.savefig('output/lq_tm/plots/mean_art_per_issue.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article counts by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_count = df_R.groupby(['article_type']).count()[['file_name']]\n",
    "type_count.columns = ['type_count']\n",
    "type_count = type_count.sort_values('type_count',ascending=False)\n",
    "type_count.to_csv('output/article_types.csv', encoding='utf-8', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles per journal title \n",
    "Not relevant for LQ study. But helpful whene working with multiple journal titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals_t = df_R.groupby(['journal_title']).count()[['file_name']]\n",
    "journals_t.columns = ['journal_count']\n",
    "journals_t = journals_t.sort_values('journal_count', ascending=False)\n",
    "journals_t.to_csv('output/articles_per_journal_title.csv', encoding='utf-8', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall wordcount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = df_all['body'].apply(lambda x: len(str(x).split()))\n",
    "word_count.sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer & LDA Topic Model\n",
    "* Convert wordlists from df_all.body to Term Frequency vector. \n",
    "* tf = term frequency vector\n",
    "* lda = latent dirichlet allocation; fit using tf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.70, min_df=0.10,\n",
    "                                max_features=None)\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(df_all.body.values.astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of the stop words cut off by max_ and min_df thresholds: \n",
    "* max_df removes words that appear in more than 70% of articles and min_df removes words that appear in fewer than 10%\n",
    "* max_df removes 24 words\n",
    "* min_df removes 145,639  words\n",
    "\n",
    "To document the words that have been removed from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/stop_words_all.txt', 'w') as f:\n",
    "    for item in tf_vectorizer.stop_words_:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "Run LDA topic model. (Note: this cell may take 10+ minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 40 # set the number of topics based on GridSearchCV best model NOTE: n_topics is deprecated\n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_components=%d...\"\n",
    "      % (n_components))\n",
    "\n",
    "#define the lda function, with desired options\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=20, # number of iterations receommended by GredSearchCV best model ()\n",
    "                                learning_method='online',\n",
    "                                random_state=0)\n",
    "#fit the model\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the LDA model to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/lda_model.pk', 'wb') as pickle_file:\n",
    "    pickle.dump(lda, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload LDA model from pickle file\n",
    "You can start from the next cell in this notebook if you've previously run the LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/lda_model.pk', 'rb') as pickle_file:\n",
    "    lda = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Log Likelihood: \", lda.score(tf))\n",
    "print(\"Perplexity: \", lda.perplexity(tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top words per topic\n",
    "Function to return the top words for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 30 # how many words per topic\n",
    "topic_word_list = []\n",
    "def return_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        #topic_n = \"\\nTopic #%d:\" % topic_idx)\n",
    "        top_words = \" \".join([feature_names[i]\n",
    "                     for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        topic_word_list.append(top_words) \n",
    "    topic_df = pd.DataFrame(topic_word_list)\n",
    "    topic_df.to_csv('output/topic_words_lq_only.csv', encoding='utf-8', index=True, header=True)\n",
    "    return(topic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`topic_word_list[x]` will return the top 30 words for each topic. \n",
    "\n",
    "Save a list of the top words per topic to CSV, using the function defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "return_top_words(lda, tf_feature_names, n_top_words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most representative articles per topic\n",
    "`article_list[x]` will return the top 10 articles aligned with each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dist = lda.transform(tf)\n",
    "topic_dist_df = pd.DataFrame(topic_dist)\n",
    "df_w_topics = topic_dist_df.join(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`d` in the loop below is a counter that = topic number. \n",
    "It matches on the name of the topic columns (0, 1, 2...) from df_w_topics. Those columns (e.g., `df_w_topics[0]`) hold prevalence values for each article for each topic. The loop below transfers the articles with the highest ten prevalence values for each article to an article_list dataframe with key article metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_list = []\n",
    "for d in range(n_components): \n",
    "    tup = df_w_topics[['article_jcode', 'article_title', 'article_type', 'journal_title', 'journal_jcode', 'pub_year', d]].sort_values(by=[d], ascending=False)[0:10]\n",
    "    #print(f'{d}: {tup}')\n",
    "    article_list.append(tup)\n",
    "    article_list[d].columns = ['article_jcode', 'article_title', 'article_type', 'journal_title', 'journal_jcode', 'pub_year', 'prevalence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the list of article_list dataframes into a single dataframe adding a column with the topic number for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in enumerate(article_list):\n",
    "    i['topic'] = n\n",
    "article_lists_df = pd.concat(article_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add book review titles\n",
    "Find the titles of book reviews in the JSTOR XML since they aren't included in the R metadata (notebook 1) and append those titles to the top articles list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list = []\n",
    "for index, row in article_lists_df[article_lists_df['article_title']==''].iterrows():\n",
    "    #insert jstor code to pull book name and author from XML\n",
    "    review_list.append(row['article_jcode'])\n",
    "reviews_df_list = []\n",
    "for xml_file in glob.iglob(\"metadata/*.xml\"):\n",
    "    jid = re.search(r'(\\d*).xml$', xml_file).group(1) # jid (formerly xid) is the jstor code, it seems\n",
    "    if jid not in review_list:\n",
    "        continue\n",
    "    tree = ET.parse(xml_file)\n",
    "    for book_reviewed_node in tree.getroot().findall('./front/article-meta/product/source'):\n",
    "        tup = (jid, book_reviewed_node.text)\n",
    "        print(tup)\n",
    "        reviews_df_list.append(tup)\n",
    "\n",
    "reviews_df = pd.DataFrame(reviews_df_list, columns=['jid', 'book_reviewed'])\n",
    "\n",
    "article_lists_df = article_lists_df.merge(reviews_df, how='outer', left_on='article_jcode', right_on='jid')\n",
    "article_lists_df = article_lists_df.drop(['jid'], axis=1)\n",
    "article_lists_df.loc[article_lists_df['article_type']=='book-review', 'article_title'] = article_lists_df['book_reviewed']\n",
    "article_lists_df = article_lists_df.drop(['book_reviewed'], axis=1)\n",
    "article_lists_df = article_lists_df.sort_values(by=['topic', 'prevalence'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any duplicate rows and save the top articles to CSV for closer analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_lists_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_lists_df.to_csv('output/top_articles_per_topic_lq.csv', encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional alternative: print output to multiple CSV files (one for each topic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, df in enumerate(article_list):\n",
    "    filename = 'output/articles_per_topic/top_articles_' + str(index) + '.csv'\n",
    "    df.to_csv(filename, encoding='utf-8', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map topics over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First calculate word count per article and multiply topic weight by word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_topics['word_count'] = df_w_topics['body'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = []\n",
    "for num in range(n_components): # This was originally called topic_columns. Not sure why yet... --naughton\n",
    "    col = \"%d_wc\" % num\n",
    "    col_list.append(col)\n",
    "    df_w_topics[col] = df_w_topics[num] * df_w_topics['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prevalence per topic\n",
    "`e` in the loop below is a counter that = topic number + '\\_wc'. It matches on the name of the topic columns (0_wc, 1_wc...) from df_w_topics. Those columns (e.g., df_w_topics[0_wc]) hold topic weights relative to word counts for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence = []\n",
    "for index, e in enumerate(col_list): \n",
    "    prev = df_w_topics[e].sum()/df_w_topics['word_count'].sum()\n",
    "    tup = (index,prev)\n",
    "    prevalence.append(tup)\n",
    "prevalence = pd.DataFrame(prevalence)\n",
    "prevalence.columns = ['topic','prevalence']\n",
    "prevalence.sort_values(by=['prevalence'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence.to_csv('output/prevalence_per_topic_lq.csv', encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map prevalence of each topic by publication year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_year = df_w_topics.groupby('pub_year')\n",
    "fig3 = plt.figure()\n",
    "# divide the number of topic words in each year by the total word count per year (so the figure adjusts to each year's output)\n",
    "for e in col_list:\n",
    "    ax2 = fig3.add_subplot(1,1,1)\n",
    "    (grouped_year[e].sum()/grouped_year['word_count'].sum()).plot(kind='line', title=e)\n",
    "    fig3.tight_layout()\n",
    "    #plt.show()\n",
    "    filename = 'output/plots/plot_' + str(e) + '.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document term matrix\n",
    "Create document-term-matrix dataframe, dtm_df, to look at the following (ignoring topic models):\n",
    "* most common words in corpus\n",
    "* average number of times each word is used in an article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_df = pd.DataFrame(tf_vectorizer.fit_transform(df_all.body.values.astype('U')).toarray(), columns=tf_vectorizer.get_feature_names(), index = df_all.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common words in corpus + avg times each is used in an article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words = dtm_df.sum().sort_values(ascending=False)[0:500]\n",
    "avg_times_used = dtm_df.mean().sort_values(ascending=False)[0:500]\n",
    "df_top = pd.DataFrame(most_common_words)\n",
    "df_top.columns = ['word_count']\n",
    "df_top['avg_used'] = avg_times_used\n",
    "df_top.to_csv('output/top_words_lq.csv', encoding='utf-8', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To explore metadata for individual articles\n",
    "For easy reference to the full metadata for each article contained in df_all using \"article_jcode,\" which is the first column in article_lists_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_10_1 = df_all[df_all['article_jcode'].str.contains('4309398')]\n",
    "topic_10_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alt: Create topic model viz\n",
    "* Use pyLDA vis to visualize alternate topics generated via scikit-learn\n",
    "* outputs to html file for future reference outside of notebook\n",
    "* pyLDAvis is based on LDAvis (for R) and using \"relevance\" method for ranking terms within a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "p = pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)\n",
    "pyLDAvis.save_html(p,'output/lda_tm_lq.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
